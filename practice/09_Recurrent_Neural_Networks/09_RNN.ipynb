{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Example\n",
    "\n",
    "Build a recurrent neural network (LSTM) with PyTorch.\n",
    "\n",
    "- Author: Ritchie Ng (some changes to the original though)\n",
    "- Project: https://github.com/ritchieng/deep-learning-wizard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Overview\n",
    "\n",
    "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" alt=\"nn\" style=\"width: 600px;\"/>\n",
    "\n",
    "References:\n",
    "- [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf), Sepp Hochreiter & Jurgen Schmidhuber, Neural Computation 9(8): 1735-1780, 1997.\n",
    "\n",
    "## MNIST Dataset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png\" alt=\"MNIST Dataset\" style=\"width: 300px;\"/>\n",
    "\n",
    "To classify images using a recurrent neural network, we consider every image row as a sequence of pixels. Because MNIST image shape is 28*28px, we will then handle 28 sequences of 28 timesteps for every sample.\n",
    "\n",
    "More info: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import dependencies\n",
    "At the beginning of every project, we first import all the required dependencies to process the data, define the model, train the model and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading\n",
    "To train our model to recognize (classify) handwritten digits, we download the famous MNIST dataset from a PyTorch collection of example datasets. The dataset consists of a training dataset (train split) and a independent test dataset (test split). Each split is a collection of tuples, whereas every tuple consists of an input image with 28x28 pixels and a target value (label) representing the value of the handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first input image of the dataset\n",
    "plt.imshow(train_dataset[0][0].squeeze())\n",
    "plt.show()\n",
    "\n",
    "# Print the associated ground truth value (label)\n",
    "print(f\"The ground truth label for the given image is: {train_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Definition\n",
    "We define a neural network consisting of multiple consecutive LSTM cells and a final fully connected layer to predict a digit given an image of a handwritten digit. The initial hidden state and cell state are initialized with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your LSTM\n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        \n",
    "        # 28 time steps\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, _ = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        \n",
    "        # Index hidden state of last step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last step!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Initialization\n",
    "The model is initialized to expect an input sequence of length 28 and predict a probability value for the digits 0-9. The model consist of a single LSTM layer with a feature dimension of 64 for the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension of the input data (sequence of 28 pixels)\n",
    "input_dim = 28\n",
    "\n",
    "# Dimemsion of the hidden state\n",
    "hidden_dim = 64\n",
    "\n",
    "# Number of LSTM layers\n",
    "layer_dim = 1\n",
    "\n",
    "# Dimension of the output data (digits 0-9)\n",
    "output_dim = 10\n",
    "\n",
    "# Model initialization\n",
    "model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training Setup\n",
    "A cross-entropy loss function is used for the model training and the model weights are optimized using a stochastic gradient descent method with a learning rate (step size) of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the loss function (cross-entropy for regression problem)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Learning rate for the model training (optimization)\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Definition of the optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacht size for model training (size of the mini batches)\n",
    "batch_size = 100\n",
    "\n",
    "# Make the datasets iterable\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of steps to unroll (28 times 28 pixels)\n",
    "seq_dim = 28  \n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 2\n",
    "\n",
    "iteration = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Load images as a torch tensor with gradient accumulation abilities\n",
    "        images = images.view(-1, seq_dim, input_dim).requires_grad_()\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        # outputs.size() --> 100, 10\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        # Evaluate model performance\n",
    "        if iteration % 100 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Resize images\n",
    "                images = images.view(-1, seq_dim, input_dim)\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iteration, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Select arbitrary test image\n",
    "image = test_dataset[0][0]\n",
    "\n",
    "# Resize image\n",
    "image = image.view(-1, seq_dim, input_dim)\n",
    "\n",
    "# Forward pass only to get logits/output\n",
    "outputs = model(image)\n",
    "\n",
    "# Get predictions from the maximum value\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Visualize the test image (model input)\n",
    "plt.imshow(image.squeeze())\n",
    "plt.show()\n",
    "\n",
    "# Print the predicted value\n",
    "print(f\"The predicted value for the given image is: {predicted}\")"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "04d5e99945ec496488032a6288c24305",
   "lastKernelId": "c66de9ba-7ff3-4ced-b0ad-3e2cfba494f5"
  },
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
