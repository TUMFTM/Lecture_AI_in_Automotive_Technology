{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc9ca03b",
   "metadata": {},
   "source": [
    "# Homework 11 - Reinforcement Learning\n",
    "\n",
    "In this homework, we consider the grid world shown in the lecture and the random policy, that assigns equal probability 1/4 to each action.\n",
    "![title](../doc/homework_11_img/environment.png) \n",
    "![title](../doc/homework_11_img/policy.png)\n",
    "\n",
    "Implement a slightly changed version of the iterative policy evaluation algorithm which can be seen below. The changes are \n",
    "\n",
    "1. the algorithm will not run to convergence, but for a certain number of episodes $N$ \n",
    "2. the value function is updated immediately for each state, instead of saving an old $V_k$ and new $V_{k+1}$\n",
    "\n",
    "The update is thus $V_{new}(x_k) = \\sum_i \\pi(u_i|x_k) (r_{t+1} + V(x_{t+1})|x_t=x_i)$, $V(x_k) = V_{new}(x_k)$. Initialize V as a numpy array of zeros. Iterate starting at state $x=0$ to state $x=10$. We consider the undiscount case ($\\gamma = 1$).\n",
    "\n",
    "![title](../doc/homework_11_img/iteration.png)\n",
    "\n",
    "The function to implement is called 'pol_eval' and takes a single input $N$ describing the number of iterations over all states. The function returns a numpy array $V$, which contains $V(x_i)$ in the $V[i]$.\n",
    "\n",
    "The environment is available and can be called as $x2, r = \\text{gridworld}(x, u)$, the same way as in the code example after the lecture. Use this notebook to implement and test your code and input the desired solution in Moodle.\n",
    "\n",
    "**Function Name:** pol_eval\n",
    "\n",
    "**Function Input Name(s):** N\n",
    "\n",
    "**Function Input Type(s):** integer > 0\n",
    "\n",
    "**Output Type:** numpy array with 12 entries of type float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181720e",
   "metadata": {},
   "source": [
    "## Environment\n",
    "This function defines the grid world environment presented in the lecture. The actions are defined as follows:  \n",
    "u = 0: go right  \n",
    "u = 1: go up  \n",
    "u = 2: go left  \n",
    "u = 3: go down  \n",
    "The input is the current state $x$ and the chosen action $u$, the output is the next state $x2$ and the reward $r$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gridworld(x, u):\n",
    "    # Transition Matrix\n",
    "    T = np.array([\n",
    "        [0, 1, 0, 0],\n",
    "        [1, 2, 1, 0],\n",
    "        [3, 2, 2, 1],\n",
    "        [8, 4, 2, 3],\n",
    "        [5, 4, 4, 3],\n",
    "        [6, 5, 4, 8],\n",
    "        [6, 6, 5, 7],\n",
    "        [7, 6, 8, 10],\n",
    "        [7, 5, 3, 9],\n",
    "        [10, 8, 9, 9],\n",
    "        [10, 7, 9, 11],\n",
    "        [11, 11, 11, 11]\n",
    "    ], dtype = int)\n",
    "    \n",
    "    # Get the next state\n",
    "    x2 = T[x, u]\n",
    "    \n",
    "    # Reward\n",
    "    r = -1\n",
    "    if x2 in [8, 9]:\n",
    "        r = -2\n",
    "    elif x == 11:\n",
    "        r = 0\n",
    "    \n",
    "    # Return the next state and reward\n",
    "    return x2, r\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a2a14",
   "metadata": {},
   "source": [
    "## Policy Evaluation\n",
    "Write your function in here, the return value should be a numpy array of length 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca0fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pol_eval(N):\n",
    "    # insert your code here\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752acaa",
   "metadata": {},
   "source": [
    "The implemented function will be called for different values of iterations. A run over 2000 iterations should produce the converged result V = [-126.5 -122.5 -114.5 -102.5 -100 -93.5 -87.5 -77.5 -88 -73.5 -52 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401a6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = [10, 50, 100, 2000]\n",
    "\n",
    "for N in iterations:\n",
    "    V = pol_eval(N)\n",
    "    print(f\"The value function for {N} iterations: \\n {V} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
