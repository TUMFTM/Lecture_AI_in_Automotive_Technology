{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10 - Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a pseudo-random number generator to set the values for the inputs. \n",
    "To make sure that we all get the same results, we have to set a seed for the pseudo-random number generator. \n",
    "\n",
    "**DO NOT CHANGE THE SEED!**\n",
    "\n",
    "The seed will probably change from semester to semester. Please make sure that this is the notebook for the current semester!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this homework we only need numpy\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for the pseudo-random number generator.\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of a softmax function\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "\n",
    "def softmax(x: np.ndarray, axis=None) -> np.ndarray:\n",
    "    \"\"\"Compute the softmax function.\n",
    "\n",
    "    The softmax function transforms each element of a collection by\n",
    "    computing the exponential of each element divided by the sum of the\n",
    "    exponentials of all the elements.\n",
    "\n",
    "    Reference: https://github.com/scipy/scipy/blob/v1.11.4/scipy/special/_logsumexp.py#L131-L225\n",
    "\n",
    "    Arguments:\n",
    "        x : Input array.\n",
    "        axis : int or tuple of ints, optional\n",
    "            Axis to compute values along. Default is None and softmax will be\n",
    "            computed over the entire array `x`.\n",
    "\n",
    "    Returns:\n",
    "        s: An array the same shape as `x`. The result will sum to 1 along the\n",
    "            specified axis.\n",
    "    \"\"\"\n",
    "    x_max = np.amax(x, axis=axis, keepdims=True)\n",
    "    exp_x_shifted = np.exp(x - x_max)\n",
    "    return exp_x_shifted / np.sum(exp_x_shifted, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled dot-product attention\n",
    "In this exercise you will write a Python function to evaluate the forward pass of a simple scaled dot-product attention.\n",
    "\n",
    "The function is defined as:  \n",
    "$\\mathbf{Y} = \\mathnormal{scaled\\_dot\\_product\\_attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V})$\n",
    "\n",
    "All inputs into the function as well as the outputs are numpy arrays, with shape  \n",
    "- Query: $\\mathbf{Q} \\in \\mathbb{R}^{m \\times d_k}$\n",
    "- Key: $\\mathbf{K} \\in \\mathbb{R}^{n \\times d_k}$\n",
    "- Value: $\\mathbf{V} \\in \\mathbb{R}^{n \\times d_v}$\n",
    "- Output: $\\mathbf{Y} \\in \\mathbb{R}^{n \\times d_v}$\n",
    "\n",
    "You can use the following template for the function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(Q: np.ndarray, K: np.ndarray, V: np.ndarray) -> np.ndarray:\n",
    "    # YOU CAN MAKE YOUR CHANGES HERE:\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    # STOP WITH CHANGES HERE.\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create pseudo-random inputs for the function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the pseudo-random input values\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "\n",
    "# Queries with dim: m x dk\n",
    "Q = np.random.rand(5, 2)\n",
    "\n",
    "# Keys with dim: n x dk\n",
    "K = np.random.rand(4, 2)\n",
    "\n",
    "# Values with dim: n x dv\n",
    "V = np.random.rand(4, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we print the outputs of your function implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing of the results\n",
    "# DO NOT CHANGE ANYTHING HERE.\n",
    "\n",
    "print(scaled_dot_product_attention(Q, K, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for the requested output element in the Moodle question and enter your result with the required precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
